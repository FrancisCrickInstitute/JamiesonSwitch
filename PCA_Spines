import pandas as pd
from sklearn.decomposition import PCA
from sklearn.preprocessing import StandardScaler
from sklearn.cluster import KMeans
import umap
import os

# Load the merged CSV file
file_path = 'FILEPATH.csv'
print(f"Loading data from {file_path}...")
df = pd.read_csv(file_path)
print(f"Data loaded successfully. Shape: {df.shape}")

# List of columns for clustering (morphometric features)
clustering_columns = [
    'Spine Part Volume Ground', 'Spine Part Mean Diameter Head', 'Spine Part Mean Diameter Ground',
    'Spine Part Max Diameter Head', 'Spine Volume', 'Spine Part Volume Neck', 'Spine Branchings',
    'Spine Part Length Ground', 'Spine Part Max Diameter Neck', 'Spine Part Length Neck',
    'Spine Part Volume Head', 'Spine Part Max Diameter Ground', 'Spine Area', 'Spine Part Length Head',
    'Spine Part Mean Diameter Neck'
]

# Select the columns for clustering and drop rows with missing data in those columns
print("Selecting columns for clustering...")
X = df[clustering_columns].dropna()
print("Columns selected. Shape of clustering data:", X.shape)

# Standardize the data before applying PCA and K-means
print("Standardizing the data...")
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)
print("Data standardized.")

# Perform K-means clustering
print("Performing K-means clustering...")
kmeans = KMeans(n_clusters=4, random_state=42)
clusters = kmeans.fit_predict(X_scaled)
print("K-means clustering completed.")

# Assign cluster labels back to the original dataframe (only for rows without NaNs)
df.loc[X.index, 'Cluster'] = clusters

# Perform PCA for dimensionality reduction
print("Performing PCA...")
pca = PCA(n_components=2)
pca_coordinates = pca.fit_transform(X_scaled)
df.loc[X.index, 'PCA1'] = pca_coordinates[:, 0]
df.loc[X.index, 'PCA2'] = pca_coordinates[:, 1]
print("PCA completed.")

# Extract PCA loadings (feature contributions)
loadings = pd.DataFrame(pca.components_.T, columns=[f'PC{i+1}' for i in range(pca.n_components_)], index=clustering_columns)
print("\nPCA Loadings (feature contributions):")
print(loadings)

# Save PCA loadings to CSV
loadings_file = 'FILEPATH_PCA_Loadings.csv'
loadings.to_csv(loadings_file)
print(f"PCA loadings saved to {loadings_file}")

# Perform UMAP for dimensionality reduction and visualization
print("Performing UMAP...")
umap_model = umap.UMAP(n_components=2, random_state=42)
umap_coordinates = umap_model.fit_transform(X_scaled)
df.loc[X.index, 'UMAP1'] = umap_coordinates[:, 0]
df.loc[X.index, 'UMAP2'] = umap_coordinates[:, 1]
print("UMAP completed.")

# Classify the rows based on the given criteria
print("Classifying spine types...")
def classify_spine_type(row):
    total_length = row['Spine Part Length Ground'] + row['Spine Part Length Neck'] + row['Spine Part Length Head']
    if total_length < 1:
        return 'Stubby'
    elif total_length > 3:
        return 'Filopodia'
    elif 1 <= total_length <= 3:
        if row['Spine Part Max Diameter Head'] > row['Spine Part Max Diameter Neck']:
            return 'Mushroom'
        else:
            return 'Thin'
    return 'Other'  # fallback

df['Spine Type'] = df.apply(classify_spine_type, axis=1)
print("Spine types classified.")

# Merge Filament Length (sum) with the original dataframe based on FilamentID and Source File
print("Merging Filament Length (sum) with the dataframe...")
unique_filament_length = df[['FilamentID', 'Source File', 'Filament Length (sum)']].drop_duplicates()
df = df.merge(unique_filament_length, on=['FilamentID', 'Source File'], how='left')
print("Filament Length (sum) merged.")

# Save the dataframe with the new columns to a new file
output_file = 'FILEPATH_with_clustering_and_spine_type.csv'
print(f"Saving the dataframe to {output_file}...")
df.to_csv(output_file, index=False)
print("Dataframe saved.")

# 1. Create file showing number of spine types per FilamentID with source file
print("Creating file for spine types per FilamentID with source file...")
spine_types_per_filament = df.groupby(['FilamentID', 'Spine Type', 'Source File']).size().reset_index(name='Count')

spine_types_per_filament_file = 'FILEPATH_Spine_Types_Per_Filament.csv'
spine_types_per_filament.to_csv(spine_types_per_filament_file, index=False)
print(f"Spine types per FilamentID saved to {spine_types_per_filament_file}.")

# 2. Merge Spine Length (sum) into spine_types_per_filament
print("Merging Spine Length (sum) into the Spine Types Per Filament file...")
spine_types_per_filament = spine_types_per_filament.merge(unique_filament_length, on=['FilamentID', 'Source File'], how='left')

# 3. Create file showing cluster counts per FilamentID with source file
print("Creating file for cluster counts per FilamentID with source file...")
cluster_counts_per_filament = df.groupby(['FilamentID', 'Cluster', 'Source File']).size().reset_index(name='Cluster Count')

cluster_counts_per_filament_file = 'FILEPATH_Cluster_Counts_Per_Filament.csv'
cluster_counts_per_filament.to_csv(cluster_counts_per_filament_file, index=False)
print(f"Cluster counts per FilamentID saved to {cluster_counts_per_filament_file}.")

# 4. Merge cluster counts into spine_types_per_filament
print("Merging cluster counts into the Spine Types Per Filament file...")
spine_types_per_filament = spine_types_per_filament.merge(
    cluster_counts_per_filament[['FilamentID', 'Cluster', 'Cluster Count']],
    on=['FilamentID', 'Cluster'], how='left'
)

spine_types_per_filament_final_file = 'FILEPATH_Spine_Types_Per_Filament_Updated.csv'
spine_types_per_filament.to_csv(spine_types_per_filament_final_file, index=False)
print(f"Updated Spine Types Per Filament file saved to {spine_types_per_filament_final_file}.")

# 5. Create file showing counts of cluster numbers associated with spine types
print("Creating file for cluster-spine type counts...")
cluster_spine_type_counts = df.groupby(['Spine Type', 'Cluster']).size().unstack(fill_value=0)
print("Cluster-spine type counts file created.")

cluster_spine_type_counts_file = 'FILEPATH_Cluster_Spine_Type_Counts.csv'
cluster_spine_type_counts.to_csv(cluster_spine_type_counts_file)
print(f"Cluster-spine type counts saved to {cluster_spine_type_counts_file}.")

print("Clustering, PCA, UMAP, classification, and CSV file generation completed successfully!")
